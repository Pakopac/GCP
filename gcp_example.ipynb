{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class DataHandler:\n",
    "    \"\"\"\n",
    "        Get data from GSC Bucket \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.csvfile1 = None\n",
    "        self.csvfile2 = None\n",
    "        self.gouped_data = None\n",
    "    def get_data(self):\n",
    "        print(\" - - - fetch data from gcs bucket : - - - \")\n",
    "        listing = pd.read_csv('https://storage.googleapis.com/h3-data/listings_final.csv', sep=';')\n",
    "        prices = pd.read_csv('https://storage.googleapis.com/h3-data/price_availability.csv', sep=';')\n",
    "        self.csvfile1, self.csvfile2 = listing, prices  \n",
    "        return \" - - - data loaded - - - \\nFiles : \\n  - listing {} \\n  - prices {}\".format(listing.shape,prices.shape)\n",
    "    def group_data(self):\n",
    "        data = self.csvfile2.groupby('listing_id')['local_price'].mean()\n",
    "        self.gouped_data = pd.merge(data, self.csvfile1, on='listing_id')\n",
    "        print(\" - - - data merged - - - \")\n",
    "    def get_process_data(self):\n",
    "        self.get_data()\n",
    "        self.group_data()\n",
    "        print(\" - - - data processed - - - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - - - fetch data from gcs bucket : - - - \n",
      " - - - data merged - - - \n",
      " - - - data processed - - - \n",
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 6.68 µs\n"
     ]
    }
   ],
   "source": [
    "data = DataHandler()\n",
    "data.get_process_data()\n",
    "%time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "class FeatureRecipe(DataHandler):\n",
    "    \"\"\"\n",
    "    Feature processing class\n",
    "    \"\"\"\n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.data = data\n",
    "        self.category = None\n",
    "        self.discrete_variable = None\n",
    "        self.continous_variable = None\n",
    "        \n",
    "    #Useless feature\n",
    "    def drop_useless(self):\n",
    "        \"\"\"\n",
    "        Drop useless column\n",
    "        \"\"\"\n",
    "\n",
    "        def drop_specific_col(self):\n",
    "            dropped_sepcific_col = []\n",
    "            dropped_sepcific_col.append('name')\n",
    "            dropped_sepcific_col.append('Unnamed: 0')\n",
    "            logging.debug(\"name and Unamed: 0 columns are useless\")\n",
    "            return dropped_sepcific_col\n",
    "               \n",
    "        def drop_nan_col(self):\n",
    "            dropped_nan_col = [] \n",
    "            for (columnName, columnData) in self.data.iteritems(): \n",
    "                if(self.data[columnName].isna().all() == True):\n",
    "                    dropped_nan_col.append(columnName)\n",
    "            logging.debug(\"{} feature have 100% NaN \".format(len(dropped_nan_col)))\n",
    "            return dropped_nan_col\n",
    "                \n",
    "        self.data = self.data.drop(drop_specific_col(self), axis=1)\n",
    "        self.data = self.data.drop(drop_nan_col(self), axis=1)\n",
    "        print(\"- - - drop useless columns - - - \")\n",
    "        \n",
    "    def deal_duplicate(self):\n",
    "        def drop_duplicate_col(self):\n",
    "            duplicated_col = self.data.loc[:,~self.data.columns.duplicated()]\n",
    "            logging.debug(\"{} feature are duplicated \".format(len(duplicated_col)))\n",
    "            return duplicated_col\n",
    "        self.data = drop_duplicate_col(self)\n",
    "        print(\"- - - drop duplicated index - - - \")\n",
    "    \n",
    "    \n",
    "    #NaN\n",
    "    def drop_nanp(self, thresold: float):\n",
    "        \"\"\"\n",
    "        Drop NaN columns according to a thresold\n",
    "        \"\"\"\n",
    "        def deal_nanp(df:pd.DataFrame, thresold: float):\n",
    "            bf=[]\n",
    "            for c in self.data.columns.to_list():\n",
    "                if self.data[c].isna().sum()/self.data.shape[0] > thresold:\n",
    "                    bf.append(c)\n",
    "            logging.debug(\"{} feature have more than {} NaN \".format(len(bf), thresold))\n",
    "            logging.debug('\\n\\n - - - features - - -  \\n {}'.format(bf))\n",
    "            return bf \n",
    "        self.data = self.data.drop(deal_nanp(self.data, thresold), axis=1)\n",
    "        logging.debug('Some NaN features droped according to {} thresold'.format(thresold))\n",
    "            \n",
    "    #Separate feature for feature engineering\n",
    "    def separate_variable_types(self) -> None:\n",
    "        \"\"\"\n",
    "        Sépare les colonnes en catégorie, variable discrète et variable continue\n",
    "        \"\"\"\n",
    "        def get_discrete_variable(self):\n",
    "            self.data.update(self.data.select_dtypes(include='bool').astype('int64'))\n",
    "            return self.data.select_dtypes(include='int64')\n",
    "            \n",
    "        def get_continous_variable(self):\n",
    "            return self.data.select_dtypes(include='float64')\n",
    "            \n",
    "        def get_category(self):\n",
    "            return self.data.select_dtypes(include='object')\n",
    "            \n",
    "        self.discrete_variable = get_discrete_variable(self)\n",
    "        self.continous_variable = get_continous_variable(self)\n",
    "        self.category = get_category(self)\n",
    "        print(\"- - - separate variable types - - - \")\n",
    "\n",
    "    #Datetime\n",
    "    def deal_dtime(self):\n",
    "        pass\n",
    "    \n",
    "    def prepare_data(self, thresold: float):\n",
    "        \"\"\"\n",
    "        Wrap code above\n",
    "        \"\"\"\n",
    "        self.drop_useless()\n",
    "        self.deal_duplicate()\n",
    "        self.drop_nanp(thresold)\n",
    "        self.separate_variable_types()\n",
    "        self.deal_dtime()\n",
    "        print(\"- - - data processed - - -\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - drop useless columns - - - \n",
      "- - - drop duplicated index - - - \n",
      "- - - separate variable types - - - \n",
      "- - - data processed - - -\n",
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 7.39 µs\n"
     ]
    }
   ],
   "source": [
    "recipe = FeatureRecipe(data.gouped_data)\n",
    "recipe.prepare_data(0.06)\n",
    "%time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    \"\"\"\n",
    "    Feature Extractor class\n",
    "    \"\"\"    \n",
    "    def __init__(self, data: pd.DataFrame, flist: list):\n",
    "        \"\"\"\n",
    "            Input : pandas.DataFrame, feature list to drop\n",
    "            Output : X_train, X_test, y_train, y_test according to sklearn.model_selection.train_test_split\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
