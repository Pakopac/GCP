{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class DataHandler:\n",
    "    \"\"\"\n",
    "        Get data from GSC Bucket \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.csvfile1 = None\n",
    "        self.csvfile2 = None\n",
    "        self.gouped_data = None\n",
    "    def get_data(self):\n",
    "        print(\" - - - fetch data from gcs bucket : - - - \")\n",
    "        listing = pd.read_csv('https://storage.googleapis.com/h3-data/listings_final.csv', sep=';')\n",
    "        prices = pd.read_csv('https://storage.googleapis.com/h3-data/price_availability.csv', sep=';')\n",
    "        self.csvfile1, self.csvfile2 = listing, prices  \n",
    "        return \" - - - data loaded - - - \\nFiles : \\n  - listing {} \\n  - prices {}\".format(listing.shape,prices.shape)\n",
    "    def group_data(self):\n",
    "        data = self.csvfile2.groupby('listing_id')['local_price'].mean()\n",
    "        self.gouped_data = pd.merge(data, self.csvfile1, on='listing_id')\n",
    "        print(\" - - - data merged - - - \")\n",
    "    def get_process_data(self):\n",
    "        self.get_data()\n",
    "        self.group_data()\n",
    "        print(\" - - - data processed - - - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - - - fetch data from gcs bucket : - - - \n",
      " - - - data merged - - - \n",
      " - - - data processed - - - \n",
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 6.68 µs\n"
     ]
    }
   ],
   "source": [
    "data = DataHandler()\n",
    "data.get_process_data()\n",
    "%time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "class FeatureRecipe(DataHandler):\n",
    "    \"\"\"\n",
    "    Feature processing class\n",
    "    \"\"\"\n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.data = data\n",
    "        self.category = None\n",
    "        self.discrete_variable = None\n",
    "        self.continous_variable = None\n",
    "        \n",
    "    #Useless feature\n",
    "    def drop_useless(self):\n",
    "        \"\"\"\n",
    "        Drop useless column\n",
    "        \"\"\"\n",
    "\n",
    "        def drop_specific_col(self):\n",
    "            dropped_sepcific_col = []\n",
    "            dropped_sepcific_col.append('name')\n",
    "            dropped_sepcific_col.append('Unnamed: 0')\n",
    "            logging.debug(\"name and Unamed: 0 columns are useless\")\n",
    "            return dropped_sepcific_col\n",
    "               \n",
    "        def drop_nan_col(self):\n",
    "            dropped_nan_col = [] \n",
    "            for (columnName, columnData) in self.data.iteritems(): \n",
    "                if(self.data[columnName].isna().all() == True):\n",
    "                    dropped_nan_col.append(columnName)\n",
    "            logging.debug(\"{} feature have 100% NaN \".format(len(dropped_nan_col)))\n",
    "            return dropped_nan_col\n",
    "                \n",
    "        self.data = self.data.drop(drop_specific_col(self), axis=1)\n",
    "        self.data = self.data.drop(drop_nan_col(self), axis=1)\n",
    "        print(\"- - - drop useless columns - - - \")\n",
    "        \n",
    "    #def deal_duplicate(self):\n",
    "        #def drop_duplicate_col(self):\n",
    "            #duplicated_col = self.data.loc[:,~self.data.columns.duplicated()]\n",
    "            #logging.debug(\"{} feature are duplicated \".format(len(duplicated_col)))\n",
    "            #return duplicated_col\n",
    "        #self.data = drop_duplicate_col(self)\n",
    "        #print(\"- - - drop duplicated column - - - \")\n",
    "        \n",
    "    def deal_duplicate(self):\n",
    "        duplicated = []\n",
    "        def get_duplicated(self):\n",
    "            rows = []\n",
    "            for c in self.data.columns.to_list():\n",
    "                row = []\n",
    "                for l in self.data[c]:\n",
    "                    row.append(l)\n",
    "                rows.append(row)\n",
    "            \n",
    "            for i in range(0, len(rows)):    \n",
    "                for j in range(i+1, len(rows)):    \n",
    "                    if(rows[i] == rows[j]):\n",
    "                        duplicated.append(j);               \n",
    "            return duplicated\n",
    "        \n",
    "        print(self.data)\n",
    "        self.data = self.data.drop(get_duplicated(self))\n",
    "        logging.debug('{} duplicated features droped'.format(len(get_duplicated(self))))\n",
    "                      \n",
    "    #Nan\n",
    "    def drop_nanp(self, thresold: float):\n",
    "        def deal_nanp(df:pd.DataFrame, thresold: float):\n",
    "            bf=[]\n",
    "            for c in self.data.columns.to_list():\n",
    "                if self.data[c].isna().sum()/self.data.shape[0] > thresold:\n",
    "                    bf.append(c)\n",
    "            logging.debug(\"{} feature have more than {} NaN \".format(len(bf), thresold))\n",
    "            logging.debug('\\n\\n - - - features - - -  \\n {}'.format(bf))\n",
    "            return bf \n",
    "        self.data = self.data.drop(deal_nanp(self.data, thresold), axis=1)\n",
    "        logging.debug('Some NaN features droped according to {} thresold'.format(thresold))\n",
    "            \n",
    "    #Separate feature for feature engineering\n",
    "    def separate_variable_types(self) -> None:\n",
    "        \"\"\"\n",
    "        Sépare les colonnes en catégorie, variable discrète et variable continue\n",
    "        \"\"\"\n",
    "        def get_discrete_variable(self):\n",
    "            self.data.update(self.data.select_dtypes(include='bool').astype('int64'))\n",
    "            return self.data.select_dtypes(include='int64')\n",
    "            \n",
    "        def get_continous_variable(self):\n",
    "            return self.data.select_dtypes(include='float64')\n",
    "            \n",
    "        def get_category(self):\n",
    "            return self.data.select_dtypes(include='object')\n",
    "            \n",
    "        self.discrete_variable = get_discrete_variable(self)\n",
    "        self.continous_variable = get_continous_variable(self)\n",
    "        self.category = get_category(self)\n",
    "        print(\"- - - separate variable types - - - \")\n",
    "\n",
    "    #Datetime\n",
    "    def deal_dtime(self):\n",
    "        pass\n",
    "    \n",
    "    def prepare_data(self, thresold: float):\n",
    "        \"\"\"\n",
    "        Wrap code above\n",
    "        \"\"\"\n",
    "        self.drop_useless()\n",
    "        self.deal_duplicate()\n",
    "        self.drop_nanp(thresold)\n",
    "        self.separate_variable_types()\n",
    "        self.deal_dtime()\n",
    "        print(\"- - - data processed - - -\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - drop useless columns - - - \n",
      "     listing_id  local_price          type   city  \\\n",
      "0         56093   170.000000   entire_home  Paris   \n",
      "1         57207    49.952756  private_room  Paris   \n",
      "2        114543   107.374026   entire_home  Paris   \n",
      "3        149534   169.000000   entire_home  Paris   \n",
      "4        164255    75.876209   entire_home  Paris   \n",
      "..          ...          ...           ...    ...   \n",
      "994    28684174   725.175781  private_room  Paris   \n",
      "995    28709644   475.000000   entire_home  Paris   \n",
      "996    28751412   117.000000   entire_home  Paris   \n",
      "997    28774896   156.397468   entire_home  Paris   \n",
      "998    28792796    49.184211   entire_home  Paris   \n",
      "\n",
      "                    neighborhood   latitude  longitude  person_capacity  beds  \\\n",
      "0              3e arrondissement  48.867284   2.358431                4     2   \n",
      "1                      Vaugirard  48.846184   2.304455                2     1   \n",
      "2                            NaN  48.849530   2.290219                2     1   \n",
      "3                            NaN  48.866360   2.361844                4     2   \n",
      "4              3e arrondissement  48.861398   2.364299                4     2   \n",
      "..                           ...        ...        ...              ...   ...   \n",
      "994                       Ternes  48.879223   2.292382                5     0   \n",
      "995               Champs-Elysées  48.872202   2.298349                4     2   \n",
      "996                      Monceau  48.880923   2.314568                2     1   \n",
      "997  Invalides - Ecole Militaire  48.852915   2.314519                2     1   \n",
      "998          Madeleine - Vendôme  48.870109   2.321475                6     4   \n",
      "\n",
      "     bedrooms  bathrooms  is_rebookable  is_new_listing  is_fully_refundable  \\\n",
      "0           1        1.0          False           False                 True   \n",
      "1           1        1.0          False           False                 True   \n",
      "2           1        1.0          False           False                 True   \n",
      "3           1        1.0          False           False                 True   \n",
      "4           1        1.0          False           False                 True   \n",
      "..        ...        ...            ...             ...                  ...   \n",
      "994         1        1.0          False            True                 True   \n",
      "995         1        1.0          False            True                 True   \n",
      "996         0        1.0          False            True                 True   \n",
      "997         1        1.0          False            True                 True   \n",
      "998         2        1.5          False            True                 True   \n",
      "\n",
      "     is_host_highly_rated  is_business_travel_ready  pricing_weekly_factor  \\\n",
      "0                    True                     False                   0.88   \n",
      "1                   False                     False                   0.87   \n",
      "2                    True                     False                   0.90   \n",
      "3                    True                     False                   1.00   \n",
      "4                   False                     False                   1.00   \n",
      "..                    ...                       ...                    ...   \n",
      "994                 False                     False                   1.00   \n",
      "995                 False                     False                   1.00   \n",
      "996                 False                     False                   1.00   \n",
      "997                 False                     False                   1.00   \n",
      "998                 False                     False                   1.00   \n",
      "\n",
      "     pricing_monthly_factor  \n",
      "0                       1.0  \n",
      "1                       1.0  \n",
      "2                       0.9  \n",
      "3                       0.4  \n",
      "4                       1.0  \n",
      "..                      ...  \n",
      "994                     1.0  \n",
      "995                     1.0  \n",
      "996                     1.0  \n",
      "997                     1.0  \n",
      "998                     1.0  \n",
      "\n",
      "[999 rows x 18 columns]\n",
      "- - - separate variable types - - - \n",
      "- - - data processed - - -\n",
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 7.39 µs\n"
     ]
    }
   ],
   "source": [
    "recipe = FeatureRecipe(data.gouped_data)\n",
    "recipe.prepare_data(0.06)\n",
    "%time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(FeatureRecipe, flist):\n",
    "    \"\"\"\n",
    "    Feature Extractor class\n",
    "    \"\"\"    \n",
    "    def __init__(self, data: pd.DataFrame, flist: list):\n",
    "        \n",
    "        \"\"\"\n",
    "            Input : pandas.DataFrame, feature list to drop\n",
    "            Output : X_train, X_test, y_train, y_test according to sklearn.model_selection.train_test_split\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fextractor = FeatureExtractor(recipe.data, list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
